<div align="center">
<h1>FireRedASR: å¼€æºå·¥ä¸šçº§
<br>
è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹</h1>

</div>

[[è®ºæ–‡]](https://arxiv.org/pdf/2501.14350)
[[æ¨¡å‹]](https://huggingface.co/fireredteam)
[[åšå®¢]](https://fireredteam.github.io/demos/firered_asr/)

FireRedASR æ˜¯ä¸€ç³»åˆ—å¼€æºå·¥ä¸šçº§è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹ï¼Œæ”¯æŒæ™®é€šè¯ã€ä¸­å›½æ–¹è¨€å’Œè‹±è¯­ï¼Œåœ¨å…¬å¼€çš„æ™®é€šè¯ ASR åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æ–°çš„æœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼ŒåŒæ—¶è¿˜æä¾›äº†å‡ºè‰²çš„æ­Œè¯è¯†åˆ«èƒ½åŠ›ã€‚


## ğŸ”¥ æœ€æ–°æ¶ˆæ¯
- [2025/02/17] æˆ‘ä»¬å‘å¸ƒäº† [FireRedASR-LLM-L](https://huggingface.co/fireredteam/FireRedASR-LLM-L/tree/main) æ¨¡å‹æƒé‡ã€‚
- [2025/01/24] æˆ‘ä»¬å‘å¸ƒäº† [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2501.14350)ã€[åšå®¢](https://fireredteam.github.io/demos/firered_asr/) å’Œ [FireRedASR-AED-L](https://huggingface.co/fireredteam/FireRedASR-AED-L/tree/main) æ¨¡å‹æƒé‡ã€‚


## æ–¹æ³•

FireRedASR æ—¨åœ¨æ»¡è¶³å„ç§åº”ç”¨åœºæ™¯ä¸­å¯¹å“è¶Šæ€§èƒ½å’Œæœ€ä¼˜æ•ˆç‡çš„å¤šæ ·åŒ–éœ€æ±‚ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå˜ä½“ï¼š
- FireRedASR-LLMï¼šæ—¨åœ¨å®ç°æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ï¼Œå¹¶æ”¯æŒæ— ç¼çš„ç«¯åˆ°ç«¯è¯­éŸ³äº¤äº’ã€‚å®ƒé‡‡ç”¨ç¼–ç å™¨-é€‚é…å™¨-LLMæ¡†æ¶ï¼Œå……åˆ†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ã€‚
- FireRedASR-AEDï¼šæ—¨åœ¨å¹³è¡¡é«˜æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ï¼Œå¹¶ä½œä¸ºåŸºäºLLMçš„è¯­éŸ³æ¨¡å‹ä¸­çš„æœ‰æ•ˆè¯­éŸ³è¡¨ç¤ºæ¨¡å—ã€‚å®ƒä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„ç¼–ç å™¨-è§£ç å™¨ï¼ˆAEDï¼‰æ¶æ„ã€‚

![Model](/assets/FireRedASR_model.png)


## è¯„ä¼°
ç»“æœä»¥ä¸­æ–‡çš„å­—ç¬¦é”™è¯¯ç‡ï¼ˆCER%ï¼‰å’Œè‹±æ–‡çš„è¯é”™è¯¯ç‡ï¼ˆWER%ï¼‰æŠ¥å‘Šã€‚

### å…¬å¼€æ™®é€šè¯ASRåŸºå‡†æµ‹è¯•è¯„ä¼°
| Model            | #Params | aishell1 | aishell2 | ws\_net  | ws\_meeting | Average-4 |
|:----------------:|:-------:|:--------:|:--------:|:--------:|:-----------:|:---------:|
| FireRedASR-LLM   | 8.3B | 0.76 | 2.15 | 4.60 | 4.67 | 3.05 |
| FireRedASR-AED   | 1.1B | 0.55 | 2.52 | 4.88 | 4.76 | 3.18 |
| Seed-ASR         | 12B+ | 0.68 | 2.27 | 4.66 | 5.69 | 3.33 |
| Qwen-Audio       | 8.4B | 1.30 | 3.10 | 9.50 | 10.87 | 6.19 |
| SenseVoice-L     | 1.6B | 2.09 | 3.04 | 6.01 | 6.73 | 4.47 |
| Whisper-Large-v3 | 1.6B | 5.14 | 4.96 | 10.48 | 18.87 | 9.86 |
| Paraformer-Large | 0.2B | 1.68 | 2.85 | 6.74 | 6.97 | 4.56 |

`ws` means WenetSpeech.

### å…¬å¼€ä¸­å›½æ–¹è¨€å’Œè‹±è¯­ASRåŸºå‡†æµ‹è¯•è¯„ä¼°
|Test Set       | KeSpeech | LibriSpeech test-clean | LibriSpeech test-other  |
| :------------:| :------: | :--------------------: | :----------------------:|
|FireRedASR-LLM | 3.56 | 1.73 | 3.67 |
|FireRedASR-AED | 4.48 | 1.93 | 4.44 |
|Previous SOTA Results | 6.70 | 1.82 | 3.50 |


## ä½¿ç”¨æ–¹æ³•

**æ³¨æ„ï¼šç”±äºæ¨¡å‹æ–‡ä»¶è¿‡å¤§ï¼Œæœ¬ä»“åº“ä¸åŒ…å«é¢„è®­ç»ƒæ¨¡å‹ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼š**

ä» [huggingface](https://huggingface.co/fireredteam) ä¸‹è½½æ¨¡å‹æ–‡ä»¶å¹¶å°†å…¶æ”¾ç½®åœ¨ `pretrained_models` æ–‡ä»¶å¤¹ä¸­ã€‚

å¦‚æœæ‚¨æƒ³ä½¿ç”¨ `FireRedASR-LLM-L`ï¼Œè¿˜éœ€è¦ä¸‹è½½ [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) å¹¶å°†å…¶æ”¾ç½®åœ¨ `pretrained_models` æ–‡ä»¶å¤¹ä¸­ã€‚ç„¶åè¿›å…¥ `FireRedASR-LLM-L` æ–‡ä»¶å¤¹å¹¶è¿è¡Œ `$ ln -s ../Qwen2-7B-Instruct`


### ç¯å¢ƒè®¾ç½®
åˆ›å»º Python ç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
```bash
$ git clone https://github.com/EchoJonhson/video.git
$ cd video
$ conda create --name fireredasr python=3.10
$ conda activate fireredasr
$ pip install -r requirements.txt
```

è®¾ç½® Linux PATH å’Œ PYTHONPATH
```bash
$ export PATH=$PWD/fireredasr/:$PWD/fireredasr/utils/:$PATH
$ export PYTHONPATH=$PWD/:$PYTHONPATH
```

### æ ¼å¼è½¬æ¢

**éŸ³é¢‘æ ¼å¼è½¬æ¢** - å°†éŸ³é¢‘è½¬æ¢ä¸º 16kHz 16-bit PCM æ ¼å¼
```bash
ffmpeg -i input_audio -ar 16000 -ac 1 -acodec pcm_s16le -f wav output.wav
```

**ä»è§†é¢‘æå–éŸ³é¢‘** - ä»è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘ï¼ˆå¯é€‰ï¼ŒFireRedASRå¯è‡ªåŠ¨å¤„ç†ï¼‰
```bash
ffmpeg -i input_video.mp4 -ar 16000 -ac 1 -acodec pcm_s16le -f wav output.wav
```

### å¿«é€Ÿå¼€å§‹

**å¤„ç†éŸ³é¢‘æ–‡ä»¶**
```bash
$ cd examples
$ bash inference_fireredasr_aed.sh
$ bash inference_fireredasr_llm.sh
```

**å¤„ç†è§†é¢‘æ–‡ä»¶**
```bash
$ cd examples
$ bash inference_video.sh                    # Shellè„šæœ¬ç¤ºä¾‹
$ python video_processing_example.py         # Pythonç¤ºä¾‹
```

### å‘½ä»¤è¡Œä½¿ç”¨

**éŸ³é¢‘æ–‡ä»¶å¤„ç†ï¼ˆå‘åå…¼å®¹ï¼‰**
```bash
$ speech2text.py --help
$ speech2text.py --wav_path examples/wav/BAC009S0764W0121.wav --asr_type "aed" --model_dir pretrained_models/FireRedASR-AED-L
$ speech2text.py --wav_path examples/wav/BAC009S0764W0121.wav --asr_type "llm" --model_dir pretrained_models/FireRedASR-LLM-L
```

**è§†é¢‘æ–‡ä»¶å¤„ç†**
```bash
# å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶
$ speech2text.py --video_path video.mp4 --asr_type "aed" --model_dir pretrained_models/FireRedASR-AED-L
$ speech2text.py --input_path video.mp4 --asr_type "llm" --model_dir pretrained_models/FireRedASR-LLM-L

# æ‰¹é‡å¤„ç†è§†é¢‘ç›®å½•
$ speech2text.py --video_dir videos/ --asr_type "aed" --model_dir pretrained_models/FireRedASR-AED-L

# æ··åˆå¤„ç†éŸ³é¢‘å’Œè§†é¢‘
$ speech2text.py --input_dir media/ --asr_type "aed" --model_dir pretrained_models/FireRedASR-AED-L
$ speech2text.py --input_paths audio.wav video.mp4 --asr_type "aed" --model_dir pretrained_models/FireRedASR-AED-L
```

**æ”¯æŒçš„è§†é¢‘æ ¼å¼ï¼š** MP4, AVI, MOV, MKV, FLV, WMV  
**æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼š** WAV, MP3, FLAC, M4A, AAC, OGG

### Python ä½¿ç”¨ç¤ºä¾‹

**å¤„ç†éŸ³é¢‘æ–‡ä»¶**
```python
from fireredasr.models.fireredasr import FireRedAsr

batch_uttid = ["BAC009S0764W0121"]
batch_wav_path = ["examples/wav/BAC009S0764W0121.wav"]

# FireRedASR-AED
model = FireRedAsr.from_pretrained("aed", "pretrained_models/FireRedASR-AED-L")
results = model.transcribe(
    batch_uttid,
    batch_wav_path,
    {
        "use_gpu": 1,
        "beam_size": 3,
        "nbest": 1,
        "decode_max_len": 0,
        "softmax_smoothing": 1.25,
        "aed_length_penalty": 0.6,
        "eos_penalty": 1.0
    }
)
print(results)
```

**å¤„ç†è§†é¢‘æ–‡ä»¶**
```python
from fireredasr.models.fireredasr import FireRedAsr

# ç›´æ¥å¤„ç†è§†é¢‘æ–‡ä»¶ï¼ŒFireRedASRä¼šè‡ªåŠ¨æå–éŸ³é¢‘
batch_uttid = ["my_video"]
batch_video_path = ["path/to/video.mp4"]

# FireRedASR-LLM å¤„ç†è§†é¢‘
model = FireRedAsr.from_pretrained("llm", "pretrained_models/FireRedASR-LLM-L")
results = model.transcribe(
    batch_uttid,
    batch_video_path,
    {
        "use_gpu": 1,
        "beam_size": 3,
        "decode_max_len": 0,
        "decode_min_len": 0,
        "repetition_penalty": 3.0,
        "llm_length_penalty": 1.0,
        "temperature": 1.0
    }
)
print(results)

# å¤„ç†å®Œæˆåï¼Œä¸´æ—¶æ–‡ä»¶ä¼šè‡ªåŠ¨æ¸…ç†
model.feat_extractor.cleanup_temp_files()
```

**æ··åˆå¤„ç†éŸ³é¢‘å’Œè§†é¢‘**
```python
# å¯ä»¥åœ¨åŒä¸€æ‰¹æ¬¡ä¸­æ··åˆå¤„ç†ä¸åŒæ ¼å¼çš„æ–‡ä»¶
batch_uttid = ["audio_sample", "video_sample"]
batch_media_path = ["audio.wav", "video.mp4"]

model = FireRedAsr.from_pretrained("aed", "pretrained_models/FireRedASR-AED-L")
results = model.transcribe(batch_uttid, batch_media_path, config)
```

## ğŸ› ï¸ æ‰¹é‡å¤„ç†å·¥å…·

### æ‰¹é‡è½¬å†™å·¥å…·
ä½¿ç”¨ `batch_transcribe.py` æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶ï¼š

```bash
# 1. å°†éŸ³é¢‘/è§†é¢‘æ–‡ä»¶æ”¾å…¥ Use/Input/ æ–‡ä»¶å¤¹
# 2. è¿è¡Œæ‰¹é‡å¤„ç†è„šæœ¬
$ python batch_transcribe.py

# è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
# - æ‰«æ Use/Input/ ä¸­çš„æ‰€æœ‰æ”¯æŒçš„åª’ä½“æ–‡ä»¶
# - æ™ºèƒ½é€‰æ‹©ä½¿ç”¨ AED æˆ– LLM æ¨¡å‹
# - æ‰¹é‡è¿›è¡Œè¯­éŸ³è¯†åˆ«å¤„ç†
# - ç”Ÿæˆå¤šæ ¼å¼ç»“æœï¼šTXTã€JSONæ ¼å¼
# - å°†ç»“æœä¿å­˜åˆ° Use/Output/ æ–‡ä»¶å¤¹
```

**æ”¯æŒæ ¼å¼ï¼š**
- éŸ³é¢‘ï¼šWAV, MP3, FLAC, M4A, AAC, OGG
- è§†é¢‘ï¼šMP4, AVI, MOV, MKV, FLV, WMV

### é•¿è§†é¢‘è½¬å†™å·¥å…·
ä½¿ç”¨ `long_video_transcribe.py` å¤„ç†é•¿æ—¶é—´çš„éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ï¼š

```bash
# æ™ºèƒ½é•¿è§†é¢‘å¤„ç†ï¼ˆæ¨èï¼‰
$ python long_video_transcribe.py

# è‡ªå®šä¹‰æ¨¡å‹å’Œå‚æ•°
$ python long_video_transcribe.py --model_type llm --max_duration 45

# åŠŸèƒ½ç‰¹ç‚¹ï¼š
# - ğŸ¯ è‡ªåŠ¨VADæ£€æµ‹è¯­éŸ³æ®µï¼Œæ™ºèƒ½åˆ‡åˆ†
# - âš¡ ç¡¬ä»¶ä¼˜åŒ–çš„å¹¶è¡Œå¤„ç†
# - ğŸš€ æ™ºèƒ½æ¨¡å‹åŠ è½½å’Œå†…å­˜ç®¡ç†  
# - ğŸ“„ å¤šæ ¼å¼è¾“å‡ºï¼šTXTã€SRTã€VTTå­—å¹•æ–‡ä»¶
# - ğŸ“Š è¯¦ç»†çš„å¤„ç†ç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡
# - ğŸ”„ æ–­ç‚¹ç»­ä¼ æ”¯æŒï¼Œå¤„ç†å¤±è´¥è‡ªåŠ¨æ¢å¤
```

**é•¿è§†é¢‘å¤„ç†æµç¨‹ï¼š**
1. **éŸ³é¢‘é¢„å¤„ç†** - è‡ªåŠ¨è½¬æ¢ä¸º16kHzå•å£°é“WAVæ ¼å¼
2. **æ™ºèƒ½åˆ‡ç‰‡** - ä½¿ç”¨Silero VADæ£€æµ‹è¯­éŸ³æ´»åŠ¨åŒºé—´
3. **å¹¶è¡Œè½¬å†™** - ç¡¬ä»¶ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†
4. **ç»“æœæ‹¼æ¥** - æ—¶é—´æˆ³å¯¹é½ï¼Œç”Ÿæˆå®Œæ•´æ–‡æœ¬å’Œå­—å¹•

**æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§ï¼š**
- ğŸ“ˆ è‡ªåŠ¨ç¡¬ä»¶æ£€æµ‹ï¼ˆGPU/CPUï¼‰
- ğŸ§  æ™ºèƒ½å†…å­˜ç®¡ç†
- âš¡ æ¨¡å‹é¢„åŠ è½½å’Œç¼“å­˜
- ğŸ”§ åŠ¨æ€æ‰¹å¤„ç†å¤§å°è°ƒæ•´

### ğŸ”¤ ä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ¢å¤ï¼ˆæ–°åŠŸèƒ½ï¼‰
FireRedASR ç°å·²é›†æˆä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ¢å¤åŠŸèƒ½ï¼Œè‡ªåŠ¨ä¸ºè½¬å†™æ–‡æœ¬æ·»åŠ æ ‡ç‚¹ç¬¦å·ï¼š

**æ”¯æŒçš„æ ‡ç‚¹ç¬¦å·ï¼š**
- é€—å·ï¼ˆï¼Œï¼‰ã€å¥å·ï¼ˆã€‚ï¼‰ã€é—®å·ï¼ˆï¼Ÿï¼‰
- æ„Ÿå¹å·ï¼ˆï¼ï¼‰ã€é¡¿å·ï¼ˆã€ï¼‰ã€åˆ†å·ï¼ˆï¼›ï¼‰

**ä½¿ç”¨æ–¹æ³•ï¼š**
```bash
# é•¿è§†é¢‘è½¬å†™ï¼ˆé»˜è®¤å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼‰
$ python long_video_transcribe.py

# ç¦ç”¨æ ‡ç‚¹æ¢å¤
$ python long_video_transcribe.py --disable-punctuation

# é•¿éŸ³é¢‘è½¬å†™ï¼ˆé»˜è®¤å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼‰
$ python long_audio_transcribe.py --input_audio audio.mp3 --model_dir pretrained_models/FireRedASR-AED-L

# æ‰¹é‡è½¬å†™ï¼ˆé»˜è®¤å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼‰
$ python batch_transcribe.py --disable-punctuation
```

**é«˜çº§å‚æ•°é…ç½®ï¼š**
```bash
# è‡ªå®šä¹‰æ ‡ç‚¹æ¢å¤å‚æ•°
$ python long_video_transcribe.py \
    --punctuation-model-dir /path/to/custom/model \
    --punctuation-chunk-size 512 \
    --punctuation-stride 256
```

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- âœ… è‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜æ ‡ç‚¹æ¢å¤æ¨¡å‹
- âœ… æ»‘åŠ¨çª—å£å¤„ç†é•¿æ–‡æœ¬ï¼Œæ— é•¿åº¦é™åˆ¶
- âœ… GPU/CPU è‡ªé€‚åº”ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡
- âœ… é”™è¯¯é™çº§æœºåˆ¶ï¼Œä¿è¯è½¬å†™æµç¨‹ç¨³å®š
- âœ… åŒæ—¶è¾“å‡ºåŸå§‹æ–‡æœ¬å’Œå¸¦æ ‡ç‚¹æ–‡æœ¬

**è¾“å‡ºæ–‡ä»¶ç¤ºä¾‹ï¼š**
```
output/
â”œâ”€â”€ test.txt              # åŸå§‹è½¬å†™æ–‡æœ¬
â”œâ”€â”€ test_æ ‡ç‚¹.txt         # å¸¦æ ‡ç‚¹æ–‡æœ¬
â”œâ”€â”€ test.srt              # åŸå§‹å­—å¹•æ–‡ä»¶
â””â”€â”€ test_æ ‡ç‚¹.srt         # å¸¦æ ‡ç‚¹å­—å¹•æ–‡ä»¶
```
## ğŸ“‹ ä½¿ç”¨æŠ€å·§ä¸æœ€ä½³å®è·µ

### æ¨¡å‹é€‰æ‹©å»ºè®®
| åœºæ™¯ | æ¨èæ¨¡å‹ | åŸå›  |
|------|----------|------|
| çŸ­éŸ³é¢‘ï¼ˆ< 30ç§’ï¼‰ | FireRedASR-LLM | æœ€é«˜å‡†ç¡®ç‡ |
| é•¿éŸ³é¢‘ï¼ˆ> 60ç§’ï¼‰ | FireRedASR-AED | æ›´å¥½çš„ç¨³å®šæ€§ |
| æ‰¹é‡å¤„ç† | FireRedASR-AED | é€Ÿåº¦æ›´å¿« |
| é«˜è´¨é‡è½¬å†™ | FireRedASR-LLM | è¯­è¨€ç†è§£æ›´å¥½ |

### è¾“å…¥é•¿åº¦é™åˆ¶ä¸è§£å†³æ–¹æ¡ˆ
- **FireRedASR-AED**: å»ºè®®æœ€é•¿ 60 ç§’ï¼Œè¶…è¿‡å¯èƒ½æœ‰å¹»è§‰é—®é¢˜
- **FireRedASR-LLM**: å»ºè®®æœ€é•¿ 30 ç§’ï¼Œè¶…è¿‡è¡Œä¸ºä¸ç¡®å®š
- **é•¿éŸ³é¢‘è§£å†³æ–¹æ¡ˆ**: è‡ªåŠ¨ä½¿ç”¨ `long_video_transcribe.py` å·¥å…·æ™ºèƒ½åˆ‡åˆ†å¤„ç†

### æ‰¹é‡æŸæœç´¢ä¼˜åŒ–
- ä½¿ç”¨ FireRedASR-LLM æ—¶ï¼Œç¡®ä¿è¾“å…¥è¯­éŸ³é•¿åº¦ç›¸ä¼¼
- é•¿åº¦å·®å¼‚å¤§æ—¶ï¼Œè®¾ç½® `batch_size=1` æˆ–æŒ‰é•¿åº¦æ’åº
- åˆ©ç”¨ç¡¬ä»¶ç®¡ç†å™¨è‡ªåŠ¨ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°

### æ€§èƒ½ä¼˜åŒ–æŠ€å·§
1. **ç¡¬ä»¶é…ç½®**
   - GPU å†…å­˜ â‰¥ 8GBï¼ˆLLMæ¨¡å‹ï¼‰
   - ç³»ç»Ÿå†…å­˜ â‰¥ 16GBï¼ˆé•¿éŸ³é¢‘ï¼‰
   - å­˜å‚¨ç©ºé—´é¢„ç•™éŸ³é¢‘3-5å€å¤§å°

2. **å¤„ç†ç­–ç•¥**
   - çŸ­éŸ³é¢‘ï¼šç›´æ¥å¤„ç†
   - é•¿éŸ³é¢‘ï¼šä½¿ç”¨VADè‡ªåŠ¨åˆ‡åˆ†
   - æ‰¹é‡æ–‡ä»¶ï¼šä½¿ç”¨æ‰¹é‡å¤„ç†å·¥å…·

3. **è´¨é‡æ§åˆ¶**
   - éŸ³é¢‘é¢„å¤„ç†ï¼š16kHz, å•å£°é“
   - ä½¿ç”¨VADå»é™¤é™éŸ³æ®µ
   - æ£€æŸ¥è¾“å‡ºç»Ÿè®¡ä¿¡æ¯éªŒè¯è´¨é‡


## è‡´è°¢
æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š
- [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct)
- [icefall/ASR_LLM](https://github.com/k2-fsa/icefall/tree/master/egs/speech_llm/ASR_LLM)
- [WeNet](https://github.com/wenet-e2e/wenet)
- [Speech-Transformer](https://github.com/kaituoxu/Speech-Transformer)


## å¼•ç”¨
```bibtex
@article{xu2025fireredasr,
  title={FireRedASR: Open-Source Industrial-Grade Mandarin Speech Recognition Models from Encoder-Decoder to LLM Integration},
  author={Xu, Kai-Tuo and Xie, Feng-Long and Tang, Xu and Hu, Yao},
  journal={arXiv preprint arXiv:2501.14350},
  year={2025}
}
```

#!/usr/bin/env python3
"""
FireRedASR é•¿éŸ³é¢‘è½¬æ–‡å­—å®Œæ•´æµç¨‹

åŠŸèƒ½ï¼š
- è‡ªåŠ¨å°†é•¿éŸ³é¢‘æ–‡ä»¶åˆ‡ç‰‡ï¼ˆä½¿ç”¨ WhisperX VADï¼‰
- æ‰¹é‡ä½¿ç”¨ FireRedASR æ¨¡å‹è½¬å†™
- æ‹¼æ¥æˆå®Œæ•´æ–‡å­—ç¨¿
- æ”¯æŒæ—¶é—´æˆ³å’Œå­—å¹•æ ¼å¼è¾“å‡º

ä½¿ç”¨æ–¹æ³•ï¼š
    python long_audio_transcribe.py --input_audio your_video.mp4 --model_type aed --model_dir pretrained_models/FireRedASR-AED-L
"""

import os
import sys
import json
import argparse
import subprocess
import shutil
from pathlib import Path
from datetime import datetime, timedelta
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from fireredasr.models.fireredasr import FireRedAsr
from fireredasr.utils.punctuation_restore import PunctuationRestorer
from fireredasr.utils.paragraph_segmentation import ParagraphSegmenter


class LongAudioTranscriber:
    def __init__(self, model_type="aed", model_dir=None, output_dir="long_audio_output"):
        self.model_type = model_type
        self.model_dir = model_dir
        self.output_dir = Path(output_dir)
        self.segments_dir = self.output_dir / "segments"
        self.transcripts_dir = self.output_dir / "transcripts"
        self.model = None
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.segments_dir.mkdir(parents=True, exist_ok=True)
        self.transcripts_dir.mkdir(parents=True, exist_ok=True)
        
        # æ ‡ç‚¹æ¢å¤ç›¸å…³
        self.enable_punctuation = True  # é»˜è®¤å¯ç”¨æ ‡ç‚¹æ¢å¤
        self.punctuation_restorer = None
        self.punctuation_model_dir = None
        self.punctuation_chunk_size = 256
        self.punctuation_stride = 128
        
        # åˆ†æ®µç›¸å…³
        self.enable_paragraph = False  # é»˜è®¤ä¸å¯ç”¨åˆ†æ®µ
        self.paragraph_segmenter = None
        self.paragraph_method = "rule"  # rule/semantic/hybrid
        self.min_paragraph_length = 50
        self.max_paragraph_length = 500
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
        print("ğŸ” æ£€æŸ¥ä¾èµ–...")
        
        # æ£€æŸ¥ ffmpeg
        try:
            subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True)
            print("âœ… ffmpeg å·²å®‰è£…")
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âŒ ffmpeg æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… ffmpeg")
            return False
        
        # æ£€æŸ¥ whisperx
        try:
            import whisperx
            print("âœ… whisperx å·²å®‰è£…")
        except ImportError:
            print("âŒ whisperx æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install whisperx")
            return False
        
        # æ£€æŸ¥ silero-vad
        try:
            import silero_vad
            print("âœ… silero-vad å·²å®‰è£…")
        except ImportError:
            print("âŒ silero-vad æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install silero-vad")
            return False
        
        return True
    
    def prepare_audio(self, input_path, target_sample_rate=16000):
        """å‡†å¤‡éŸ³é¢‘ï¼šè½¬æ¢ä¸º 16kHz å•å£°é“ WAV æ ¼å¼"""
        print(f"ğŸµ å‡†å¤‡éŸ³é¢‘: {input_path}")
        
        input_path = Path(input_path)
        output_path = self.output_dir / "prepared_audio.wav"
        
        # ä½¿ç”¨ ffmpeg è½¬æ¢éŸ³é¢‘
        cmd = [
            "ffmpeg", "-i", str(input_path),
            "-ar", str(target_sample_rate),
            "-ac", "1",
            "-acodec", "pcm_s16le",
            "-f", "wav",
            "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            str(output_path)
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print(f"âœ… éŸ³é¢‘å‡†å¤‡å®Œæˆ: {output_path}")
            return output_path
        except subprocess.CalledProcessError as e:
            print(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {e.stderr}")
            return None
    
    def segment_audio_with_vad(self, audio_path):
        """ä½¿ç”¨ VAD åˆ‡ç‰‡éŸ³é¢‘"""
        print("âœ‚ï¸ ä½¿ç”¨ VAD åˆ‡ç‰‡éŸ³é¢‘...")
        
        try:
            # ä½¿ç”¨ silero-vad è¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹
            import torch
            import torchaudio
            from silero_vad import load_silero_vad, read_audio, get_speech_timestamps
            
            # åŠ è½½ VAD æ¨¡å‹
            model = load_silero_vad()
            
            # è¯»å–éŸ³é¢‘
            wav = read_audio(str(audio_path))
            
            # è·å–è¯­éŸ³æ—¶é—´æˆ³
            speech_timestamps = get_speech_timestamps(
                wav, model, 
                return_seconds=True,
                min_speech_duration_ms=1000,  # æœ€å°è¯­éŸ³æ®µé•¿åº¦ 1ç§’
                max_speech_duration_s=30,     # æœ€å¤§è¯­éŸ³æ®µé•¿åº¦ 30ç§’
                min_silence_duration_ms=500   # æœ€å°é™éŸ³é—´éš” 0.5ç§’
            )
            
            print(f"ğŸ“Š æ£€æµ‹åˆ° {len(speech_timestamps)} ä¸ªè¯­éŸ³æ®µ")
            
            # ä¿å­˜åˆ†æ®µä¿¡æ¯
            segments_info = []
            
            # åˆ‡ç‰‡éŸ³é¢‘
            for i, segment in enumerate(speech_timestamps):
                start_time = segment['start']
                end_time = segment['end']
                duration = end_time - start_time
                
                # ç”Ÿæˆåˆ†æ®µæ–‡ä»¶å
                segment_filename = f"segment_{i:03d}.wav"
                segment_path = self.segments_dir / segment_filename
                
                # ä½¿ç”¨ ffmpeg åˆ‡ç‰‡
                cmd = [
                    "ffmpeg", "-i", str(audio_path),
                    "-ss", str(start_time),
                    "-t", str(duration),
                    "-acodec", "copy",
                    "-y",
                    str(segment_path)
                ]
                
                subprocess.run(cmd, capture_output=True, check=True)
                
                # è®°å½•åˆ†æ®µä¿¡æ¯
                segment_info = {
                    "id": i,
                    "filename": segment_filename,
                    "start_time": start_time,
                    "end_time": end_time,
                    "duration": duration
                }
                segments_info.append(segment_info)
                
                print(f"  âœ… åˆ†æ®µ {i:03d}: {start_time:.2f}s - {end_time:.2f}s ({duration:.2f}s)")
            
            # ä¿å­˜åˆ†æ®µä¿¡æ¯åˆ° JSON æ–‡ä»¶
            segments_json_path = self.output_dir / "segments.json"
            with open(segments_json_path, 'w', encoding='utf-8') as f:
                json.dump(segments_info, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… éŸ³é¢‘åˆ‡ç‰‡å®Œæˆï¼Œå…± {len(segments_info)} ä¸ªåˆ†æ®µ")
            print(f"ğŸ“„ åˆ†æ®µä¿¡æ¯ä¿å­˜è‡³: {segments_json_path}")
            
            return segments_info
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆ‡ç‰‡å¤±è´¥: {str(e)}")
            return None
    
    def load_fireredasr_model(self):
        """åŠ è½½ FireRedASR æ¨¡å‹"""
        if self.model is None:
            print(f"ğŸ”„ åŠ è½½ FireRedASR-{self.model_type.upper()} æ¨¡å‹...")
            start_time = time.time()
            
            try:
                self.model = FireRedAsr.from_pretrained(self.model_type, self.model_dir)
                load_time = time.time() - start_time
                print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}s)")
                return True
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                return False
        return True
    
    def get_decode_config(self):
        """è·å–è§£ç é…ç½®"""
        if self.model_type == "aed":
            return {
                "use_gpu": 1,
                "beam_size": 3,
                "nbest": 1,
                "decode_max_len": 0,
                "softmax_smoothing": 1.25,
                "aed_length_penalty": 0.6,
                "eos_penalty": 1.0
            }
        else:  # llm
            return {
                "use_gpu": 1,
                "beam_size": 3,
                "decode_max_len": 0,
                "decode_min_len": 0,
                "repetition_penalty": 3.0,
                "llm_length_penalty": 1.0,
                "temperature": 1.0
            }
    
    def transcribe_segments(self, segments_info):
        """æ‰¹é‡è½¬å†™éŸ³é¢‘åˆ†æ®µ"""
        print(f"ğŸ¯ å¼€å§‹æ‰¹é‡è½¬å†™ {len(segments_info)} ä¸ªéŸ³é¢‘åˆ†æ®µ...")
        
        if not self.load_fireredasr_model():
            return None
        
        decode_config = self.get_decode_config()
        transcription_results = []
        
        try:
            for i, segment_info in enumerate(segments_info):
                segment_filename = segment_info['filename']
                segment_path = self.segments_dir / segment_filename
                
                print(f"\n[{i+1}/{len(segments_info)}] è½¬å†™: {segment_filename}")
                
                # è½¬å†™å•ä¸ªåˆ†æ®µ
                uttid = f"segment_{i:03d}"
                start_time = time.time()
                
                results = self.model.transcribe(
                    [uttid], [str(segment_path)], decode_config
                )
                
                process_time = time.time() - start_time
                
                if results and len(results) > 0:
                    result = results[0]
                    text = result['text']
                    rtf = float(result.get('rtf', 0))
                    
                    print(f"  âœ… è½¬å†™å®Œæˆ (è€—æ—¶: {process_time:.2f}s, RTF: {rtf:.4f})")
                    print(f"  ğŸ“ ç»“æœ: {text}")
                    
                    # ä¿å­˜å•ä¸ªè½¬å†™ç»“æœ
                    transcript_filename = f"segment_{i:03d}.txt"
                    transcript_path = self.transcripts_dir / transcript_filename
                    with open(transcript_path, 'w', encoding='utf-8') as f:
                        f.write(text)
                    
                    # è®°å½•è½¬å†™ç»“æœ
                    transcription_result = {
                        "id": i,
                        "filename": segment_filename,
                        "transcript_file": transcript_filename,
                        "text": text,
                        "start_time": segment_info['start_time'],
                        "end_time": segment_info['end_time'],
                        "duration": segment_info['duration'],
                        "process_time": process_time,
                        "rtf": rtf
                    }
                    transcription_results.append(transcription_result)
                    
                else:
                    print(f"  âŒ è½¬å†™å¤±è´¥: æ²¡æœ‰è¿”å›ç»“æœ")
                    transcription_results.append(None)
            
            # ä¿å­˜è½¬å†™ç»“æœåˆ° JSON æ–‡ä»¶
            transcripts_json_path = self.output_dir / "transcripts.json"
            with open(transcripts_json_path, 'w', encoding='utf-8') as f:
                json.dump(transcription_results, f, ensure_ascii=False, indent=2)
            
            successful = len([r for r in transcription_results if r is not None])
            print(f"\nâœ… æ‰¹é‡è½¬å†™å®Œæˆ! æˆåŠŸ: {successful}/{len(segments_info)}")
            print(f"ğŸ“„ è½¬å†™ç»“æœä¿å­˜è‡³: {transcripts_json_path}")
            
            return transcription_results
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡è½¬å†™å¤±è´¥: {str(e)}")
            return None
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if self.model:
                self.model.feat_extractor.cleanup_temp_files()
    
    def merge_transcripts(self, transcription_results, output_formats=['txt', 'srt']):
        """æ‹¼æ¥è½¬å†™ç»“æœä¸ºå®Œæ•´æ–‡å­—ç¨¿"""
        print("ğŸ“ æ‹¼æ¥è½¬å†™ç»“æœ...")
        
        if not transcription_results:
            print("âŒ æ²¡æœ‰è½¬å†™ç»“æœå¯æ‹¼æ¥")
            return None
        
        # è¿‡æ»¤æ‰å¤±è´¥çš„è½¬å†™ç»“æœ
        valid_results = [r for r in transcription_results if r is not None]
        
        if not valid_results:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è½¬å†™ç»“æœ")
            return None
        
        # æŒ‰æ—¶é—´é¡ºåºæ’åº
        valid_results.sort(key=lambda x: x['start_time'])
        
        output_files = []
        
        # ç”Ÿæˆçº¯æ–‡æœ¬æ ¼å¼
        if 'txt' in output_formats:
            txt_path = self.output_dir / "full_transcript.txt"
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(f"FireRedASR é•¿éŸ³é¢‘è½¬å†™ç»“æœ\n")
                f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ä½¿ç”¨æ¨¡å‹: FireRedASR-{self.model_type.upper()}\n")
                f.write(f"æ€»æ—¶é•¿: {self.format_time(sum(r['duration'] for r in valid_results))}\n")
                f.write("=" * 60 + "\n\n")
                
                # å°†æ‰€æœ‰æ–‡æœ¬è¿æ¥æˆè¿ç»­æ®µè½
                all_text = []
                for result in valid_results:
                    text = result['text'].strip()
                    if text:  # åªæ·»åŠ éç©ºæ–‡æœ¬
                        all_text.append(text)
                
                # ä½¿ç”¨ç©ºæ ¼è¿æ¥ï¼Œå½¢æˆè¿ç»­æ–‡æœ¬
                continuous_text = ' '.join(all_text)
                f.write(continuous_text)
            
            # åŒæ—¶ä¿å­˜ä¸€ä¸ªå¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
            timestamp_txt_path = self.output_dir / "full_transcript_with_timestamps.txt"
            with open(timestamp_txt_path, 'w', encoding='utf-8') as f:
                f.write(f"FireRedASR é•¿éŸ³é¢‘è½¬å†™ç»“æœï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰\n")
                f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ä½¿ç”¨æ¨¡å‹: FireRedASR-{self.model_type.upper()}\n")
                f.write(f"æ€»åˆ†æ®µæ•°: {len(valid_results)}\n")
                f.write("=" * 60 + "\n\n")
                
                for result in valid_results:
                    start_time = result['start_time']
                    end_time = result['end_time']
                    text = result['text']
                    
                    # æ ¼å¼åŒ–æ—¶é—´
                    start_str = self.format_time(start_time)
                    end_str = self.format_time(end_time)
                    
                    f.write(f"[{start_str} - {end_str}] {text}\n\n")
            
            output_files.append(timestamp_txt_path)
            print(f"ğŸ“„ å¸¦æ—¶é—´æˆ³æ–‡æœ¬æ–‡ä»¶: {timestamp_txt_path}")
            
            output_files.append(txt_path)
            print(f"ğŸ“„ çº¯æ–‡æœ¬æ–‡ä»¶: {txt_path}")
        
        # ç”Ÿæˆ SRT å­—å¹•æ ¼å¼
        if 'srt' in output_formats:
            srt_path = self.output_dir / "full_transcript.srt"
            with open(srt_path, 'w', encoding='utf-8') as f:
                for i, result in enumerate(valid_results, 1):
                    start_time = result['start_time']
                    end_time = result['end_time']
                    text = result['text']
                    
                    # SRT æ—¶é—´æ ¼å¼
                    start_srt = self.format_time_srt(start_time)
                    end_srt = self.format_time_srt(end_time)
                    
                    f.write(f"{i}\n")
                    f.write(f"{start_srt} --> {end_srt}\n")
                    f.write(f"{text}\n\n")
            
            output_files.append(srt_path)
            print(f"ğŸ“„ SRT å­—å¹•æ–‡ä»¶: {srt_path}")
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_duration = sum(r['duration'] for r in valid_results)
        total_process_time = sum(r['process_time'] for r in valid_results)
        avg_rtf = sum(r['rtf'] for r in valid_results) / len(valid_results)
        
        stats = {
            "total_segments": len(valid_results),
            "total_duration": total_duration,
            "total_process_time": total_process_time,
            "average_rtf": avg_rtf,
            "model_type": self.model_type,
            "timestamp": datetime.now().isoformat()
        }
        
        stats_path = self.output_dir / "transcription_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š è½¬å†™ç»Ÿè®¡:")
        print(f"  æ€»åˆ†æ®µæ•°: {len(valid_results)}")
        print(f"  æ€»æ—¶é•¿: {self.format_time(total_duration)}")
        print(f"  å¤„ç†æ—¶é—´: {total_process_time:.2f}s")
        print(f"  å¹³å‡ RTF: {avg_rtf:.4f}")
        print(f"ğŸ“„ ç»Ÿè®¡ä¿¡æ¯: {stats_path}")
        
        # æ ‡ç‚¹æ¢å¤å¤„ç†
        if self.enable_punctuation:
            try:
                print(f"\nğŸ”¤ å¼€å§‹æ ‡ç‚¹æ¢å¤å¤„ç†...")
                
                # åˆå§‹åŒ–æ ‡ç‚¹æ¢å¤å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
                if self.punctuation_restorer is None:
                    self.punctuation_restorer = PunctuationRestorer(
                        cache_dir=self.punctuation_model_dir,
                        chunk_size=self.punctuation_chunk_size,
                        stride=self.punctuation_stride
                    )
                    
                # å¯¹çº¯æ–‡æœ¬è¿›è¡Œæ ‡ç‚¹æ¢å¤
                # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                full_text = '\n'.join([r['text'] for r in valid_results])
                punctuated_text = self.punctuation_restorer.restore_punctuation(full_text)
                
                # ä¿å­˜å¸¦æ ‡ç‚¹çš„çº¯æ–‡æœ¬
                if 'txt' in output_formats:
                    punctuated_txt_path = self.output_dir / "full_transcript_with_punctuation.txt"
                    with open(punctuated_txt_path, 'w', encoding='utf-8') as f:
                        f.write(f"FireRedASR é•¿éŸ³é¢‘è½¬å†™ç»“æœï¼ˆå¸¦æ ‡ç‚¹ç¬¦å·ï¼‰\n")
                        f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"ä½¿ç”¨æ¨¡å‹: FireRedASR-{self.model_type.upper()}\n")
                        f.write(f"æ€»æ—¶é•¿: {self.format_time(sum(r['duration'] for r in valid_results))}\n")
                        f.write("=" * 60 + "\n\n")
                        
                        # ç›´æ¥å†™å…¥å¸¦æ ‡ç‚¹çš„è¿ç»­æ–‡æœ¬
                        f.write(punctuated_text)
                    
                    output_files.append(punctuated_txt_path)
                    print(f"ğŸ“„ å¸¦æ ‡ç‚¹æ–‡æœ¬æ–‡ä»¶: {punctuated_txt_path}")
                
                # ç”Ÿæˆå¸¦æ ‡ç‚¹çš„ SRT å­—å¹•
                if 'srt' in output_formats:
                    punctuated_srt_path = self.output_dir / "full_transcript_with_punctuation.srt"
                    with open(punctuated_srt_path, 'w', encoding='utf-8') as f:
                        punctuated_lines = punctuated_text.split('\n')
                        for i, result in enumerate(valid_results, 1):
                            start_time = result['start_time']
                            end_time = result['end_time']
                            
                            # å°è¯•ä½¿ç”¨å¯¹åº”çš„å¸¦æ ‡ç‚¹æ–‡æœ¬
                            if i-1 < len(punctuated_lines):
                                text = punctuated_lines[i-1]
                            else:
                                text = result['text']
                            
                            # SRT æ—¶é—´æ ¼å¼
                            start_srt = self.format_time_srt(start_time)
                            end_srt = self.format_time_srt(end_time)
                            
                            f.write(f"{i}\n")
                            f.write(f"{start_srt} --> {end_srt}\n")
                            f.write(f"{text}\n\n")
                    
                    output_files.append(punctuated_srt_path)
                    print(f"ğŸ“„ å¸¦æ ‡ç‚¹å­—å¹•æ–‡ä»¶: {punctuated_srt_path}")
                
                # å¦‚æœå¯ç”¨äº†åˆ†æ®µåŠŸèƒ½
                if self.enable_paragraph and punctuated_text:
                    try:
                        print(f"\nğŸ“‘ å¼€å§‹è‡ªç„¶æ®µåˆ†æ®µå¤„ç†...")
                        
                        # åˆå§‹åŒ–åˆ†æ®µå™¨
                        if self.paragraph_segmenter is None:
                            self.paragraph_segmenter = ParagraphSegmenter(
                                min_length=self.min_paragraph_length,
                                max_length=self.max_paragraph_length
                            )
                        
                        # æ‰§è¡Œåˆ†æ®µ
                        paragraphs = self.paragraph_segmenter.segment_paragraphs(punctuated_text)
                        
                        # ä¿å­˜åˆ†æ®µç»“æœ
                        if 'txt' in output_formats:
                            paragraph_txt_path = self.output_dir / "full_transcript_paragraphs.txt"
                            with open(paragraph_txt_path, 'w', encoding='utf-8') as f:
                                f.write(f"FireRedASR é•¿éŸ³é¢‘è½¬å†™ç»“æœ\n")
                                f.write(f"\nå¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                f.write(f"ä½¿ç”¨æ¨¡å‹: FireRedASR-{self.model_type.upper()}\n")
                                f.write(f"æ€»æ—¶é•¿: {self.format_time(sum(r['duration'] for r in valid_results))}\n")
                                f.write(f"æ®µè½æ•°: {len(paragraphs)}\n")
                                f.write("\n" + "=" * 60 + "\n\n")
                                
                                # ä½¿ç”¨ä¹¦ç±æ’ç‰ˆæ ¼å¼
                                for i, para in enumerate(paragraphs, 1):
                                    # æ®µé¦–ç¼©è¿›4ä¸ªç©ºæ ¼
                                    f.write(f"    {para}\n\n")
                            
                            # åŒæ—¶ç”Ÿæˆ Markdown æ ¼å¼
                            markdown_path = self.output_dir / "full_transcript_paragraphs.md"
                            with open(markdown_path, 'w', encoding='utf-8') as f:
                                # Markdown å¤´éƒ¨
                                f.write(f"# éŸ³é¢‘è½¬å†™æ–‡ç¨¿\n\n")
                                f.write(f"**å¤„ç†æ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
                                f.write(f"**éŸ³é¢‘æ—¶é•¿:** {self.format_time(sum(r['duration'] for r in valid_results))}  \n")
                                f.write(f"**æ®µè½æ•°é‡:** {len(paragraphs)}  \n\n")
                                f.write("---\n\n")
                                
                                # æ­£æ–‡å†…å®¹
                                for i, para in enumerate(paragraphs, 1):
                                    f.write(f"{para}\n\n")
                            
                            output_files.append(markdown_path)
                            print(f"ğŸ“„ Markdown æ–‡ä»¶: {markdown_path}")
                            
                            output_files.append(paragraph_txt_path)
                            print(f"ğŸ“„ è‡ªç„¶æ®µæ ¼å¼æ–‡ä»¶: {paragraph_txt_path}")
                            print(f"   å…±åˆ†ä¸º {len(paragraphs)} ä¸ªè‡ªç„¶æ®µ")
                        
                    except Exception as e:
                        print(f"âš ï¸ åˆ†æ®µå¤„ç†å¤±è´¥: {str(e)}")
                        print("   å°†ä¿ç•™å¸¦æ ‡ç‚¹ç‰ˆæœ¬")
                    
            except Exception as e:
                print(f"âš ï¸ æ ‡ç‚¹æ¢å¤å¤±è´¥: {str(e)}")
                print("   å°†ä¿ç•™æ— æ ‡ç‚¹ç‰ˆæœ¬")
        
        return output_files
    
    def format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´ä¸º HH:MM:SS æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    
    def format_time_srt(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´ä¸º SRT æ ¼å¼ HH:MM:SS,mmm"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def process_long_audio(self, input_audio, output_formats=['txt', 'srt']):
        """å®Œæ•´çš„é•¿éŸ³é¢‘å¤„ç†æµç¨‹"""
        print("ğŸ”¥ FireRedASR é•¿éŸ³é¢‘è½¬æ–‡å­—å®Œæ•´æµç¨‹")
        print("=" * 60)
        
        # æ£€æŸ¥ä¾èµ–
        if not self.check_dependencies():
            return False
        
        # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡éŸ³é¢‘
        print("\nğŸ”¹ ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡éŸ³é¢‘")
        prepared_audio = self.prepare_audio(input_audio)
        if not prepared_audio:
            return False
        
        # ç¬¬äºŒæ­¥ï¼šåˆ‡ç‰‡éŸ³é¢‘
        print("\nğŸ”¹ ç¬¬äºŒæ­¥ï¼šVAD åˆ‡ç‰‡éŸ³é¢‘")
        segments_info = self.segment_audio_with_vad(prepared_audio)
        if not segments_info:
            return False
        
        # ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡è½¬å†™
        print("\nğŸ”¹ ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡è½¬å†™éŸ³é¢‘åˆ†æ®µ")
        transcription_results = self.transcribe_segments(segments_info)
        if not transcription_results:
            return False
        
        # ç¬¬å››æ­¥ï¼šæ‹¼æ¥ç»“æœ
        print("\nğŸ”¹ ç¬¬å››æ­¥ï¼šæ‹¼æ¥è½¬å†™ç»“æœ")
        output_files = self.merge_transcripts(transcription_results, output_formats)
        if not output_files:
            return False
        
        print("\n" + "=" * 60)
        print("âœ… é•¿éŸ³é¢‘è½¬æ–‡å­—æµç¨‹å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("ğŸ“„ è¾“å‡ºæ–‡ä»¶:")
        for file_path in output_files:
            print(f"  - {file_path}")
        
        return True


def main():
    parser = argparse.ArgumentParser(description="FireRedASR é•¿éŸ³é¢‘è½¬æ–‡å­—å®Œæ•´æµç¨‹")
    parser.add_argument('--input_audio', type=str, required=True, help="è¾“å…¥éŸ³é¢‘/è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument('--model_type', type=str, choices=['aed', 'llm'], default='aed', help="æ¨¡å‹ç±»å‹")
    parser.add_argument('--model_dir', type=str, required=True, help="æ¨¡å‹ç›®å½•è·¯å¾„")
    parser.add_argument('--output_dir', type=str, default='long_audio_output', help="è¾“å‡ºç›®å½•")
    parser.add_argument('--output_formats', type=str, nargs='+', choices=['txt', 'srt'], default=['txt', 'srt'], help="è¾“å‡ºæ ¼å¼")
    
    # æ ‡ç‚¹æ¢å¤ç›¸å…³å‚æ•°
    parser.add_argument('--enable-punctuation', action='store_true', default=True,
                        help='å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--disable-punctuation', action='store_true',
                        help='ç¦ç”¨æ ‡ç‚¹æ¢å¤')
    parser.add_argument('--punctuation-model-dir', type=str,
                        help='è‡ªå®šä¹‰æ ‡ç‚¹æ¢å¤æ¨¡å‹è·¯å¾„')
    parser.add_argument('--punctuation-chunk-size', type=int, default=256,
                        help='æ ‡ç‚¹æ¢å¤æ–‡æœ¬å—å¤§å°ï¼ˆé»˜è®¤: 256ï¼‰')
    parser.add_argument('--punctuation-stride', type=int, default=128,
                        help='æ ‡ç‚¹æ¢å¤æ»‘åŠ¨çª—å£æ­¥é•¿ï¼ˆé»˜è®¤: 128ï¼‰')
    
    # åˆ†æ®µç›¸å…³å‚æ•°
    parser.add_argument('--enable-paragraph', action='store_true',
                        help='å¯ç”¨è‡ªç„¶æ®µåˆ†æ®µåŠŸèƒ½')
    parser.add_argument('--paragraph-method', type=str, default='rule',
                        choices=['rule', 'semantic', 'hybrid'],
                        help='åˆ†æ®µæ–¹æ³•ï¼šruleï¼ˆè§„åˆ™ï¼‰ã€semanticï¼ˆè¯­ä¹‰ï¼‰ã€hybridï¼ˆæ··åˆï¼‰')
    parser.add_argument('--min-paragraph-length', type=int, default=50,
                        help='æœ€å°æ®µè½é•¿åº¦ï¼ˆé»˜è®¤: 50å­—ï¼‰')
    parser.add_argument('--max-paragraph-length', type=int, default=500,
                        help='æœ€å¤§æ®µè½é•¿åº¦ï¼ˆé»˜è®¤: 500å­—ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.input_audio).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_audio}")
        return
    
    # æ£€æŸ¥æ¨¡å‹ç›®å½•
    if not Path(args.model_dir).exists():
        print(f"âŒ é”™è¯¯: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {args.model_dir}")
        return
    
    # åˆ›å»ºè½¬å†™å™¨
    transcriber = LongAudioTranscriber(
        model_type=args.model_type,
        model_dir=args.model_dir,
        output_dir=args.output_dir
    )
    
    # è®¾ç½®æ ‡ç‚¹æ¢å¤å‚æ•°
    if args.disable_punctuation:
        transcriber.enable_punctuation = False
    else:
        transcriber.enable_punctuation = True
    
    if args.punctuation_model_dir:
        transcriber.punctuation_model_dir = args.punctuation_model_dir
    transcriber.punctuation_chunk_size = args.punctuation_chunk_size
    transcriber.punctuation_stride = args.punctuation_stride
    
    # è®¾ç½®åˆ†æ®µå‚æ•°
    transcriber.enable_paragraph = args.enable_paragraph
    transcriber.paragraph_method = args.paragraph_method
    transcriber.min_paragraph_length = args.min_paragraph_length
    transcriber.max_paragraph_length = args.max_paragraph_length
    
    # æ‰§è¡Œå®Œæ•´æµç¨‹
    success = transcriber.process_long_audio(args.input_audio, args.output_formats)
    
    if success:
        print("\nğŸ‰ å¤„ç†æˆåŠŸå®Œæˆ!")
    else:
        print("\nâŒ å¤„ç†å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()
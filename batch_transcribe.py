#!/usr/bin/env python3
"""
FireRedASR æ‰¹é‡è¯­éŸ³è¯†åˆ«è„šæœ¬

åŠŸèƒ½ï¼š
- è‡ªåŠ¨æ‰«æ Use/Input/ æ–‡ä»¶å¤¹ä¸­çš„éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
- ç”¨æˆ·é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹ï¼ˆAEDæˆ–LLMï¼‰
- æ‰¹é‡è¿›è¡Œè¯­éŸ³è¯†åˆ«è½¬æ¢
- ç»“æœä¿å­˜åˆ° Use/Output/ æ–‡ä»¶å¤¹ä¸­
- æ”¯æŒæ ¼å¼ï¼šWAV, MP3, FLAC, M4A, AAC, MP4, AVI, MOV, MKV, FLV, WMV

ä½¿ç”¨æ–¹æ³•ï¼š
    python batch_transcribe.py
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from fireredasr.models.fireredasr import FireRedAsr
from fireredasr.utils.video_audio import is_video_file, is_audio_file
from fireredasr.utils.punctuation_restore import PunctuationRestorer
from fireredasr.utils.paragraph_segmentation import ParagraphSegmenter


class BatchTranscriber:
    def __init__(self):
        self.input_dir = Path("Use/Input")
        self.output_dir = Path("Use/Output")
        self.supported_audio = {'.wav', '.mp3', '.flac', '.m4a', '.aac', '.ogg'}
        self.supported_video = {'.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv'}
        self.model = None
        self.model_type = None
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ ‡ç‚¹æ¢å¤ç›¸å…³
        self.enable_punctuation = True  # é»˜è®¤å¯ç”¨æ ‡ç‚¹æ¢å¤
        self.punctuation_restorer = None
        self.punctuation_model_dir = None
        self.punctuation_chunk_size = 256
        self.punctuation_stride = 128
        
        # åˆ†æ®µç›¸å…³ï¼ˆæ‰¹é‡æ¨¡å¼ä¸‹å¯èƒ½ç”¨å¤„ä¸å¤§ï¼Œä½†ä¿æŒæ¥å£ä¸€è‡´ï¼‰
        self.enable_paragraph = False  # é»˜è®¤ä¸å¯ç”¨åˆ†æ®µ
        self.paragraph_segmenter = None
        self.min_paragraph_length = 50
        self.max_paragraph_length = 500
    
    def scan_input_files(self):
        """æ‰«æè¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„åª’ä½“æ–‡ä»¶"""
        if not self.input_dir.exists():
            print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.input_dir}")
            print("è¯·åˆ›å»º Use/Input/ æ–‡ä»¶å¤¹å¹¶æ”¾å…¥éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶")
            return []
        
        media_files = []
        all_extensions = self.supported_audio | self.supported_video
        
        for file_path in self.input_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in all_extensions:
                media_files.append(file_path)
        
        return sorted(media_files)
    
    def display_files(self, files):
        """æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶"""
        if not files:
            print("âŒ åœ¨ Use/Input/ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„åª’ä½“æ–‡ä»¶")
            print(f"æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {', '.join(self.supported_audio)}")
            print(f"æ”¯æŒçš„è§†é¢‘æ ¼å¼: {', '.join(self.supported_video)}")
            return False
        
        print(f"\nğŸ“ åœ¨ Use/Input/ ä¸­æ‰¾åˆ° {len(files)} ä¸ªåª’ä½“æ–‡ä»¶:")
        print("-" * 60)
        
        audio_count = 0
        video_count = 0
        
        for i, file_path in enumerate(files, 1):
            file_size = file_path.stat().st_size / 1024 / 1024  # MB
            if is_audio_file(str(file_path)) or file_path.suffix.lower() in self.supported_audio:
                file_type = "ğŸµ éŸ³é¢‘"
                audio_count += 1
            else:
                file_type = "ğŸ“¹ è§†é¢‘"
                video_count += 1
            
            print(f"{i:2d}. {file_type} | {file_path.name} ({file_size:.2f} MB)")
        
        print("-" * 60)
        print(f"æ€»è®¡: {audio_count} ä¸ªéŸ³é¢‘æ–‡ä»¶, {video_count} ä¸ªè§†é¢‘æ–‡ä»¶")
        return True
    
    def select_model(self):
        """è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹"""
        print("\nğŸ¤– è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹:")
        print("1. FireRedASR-AED (å¿«é€Ÿ, é€‚åˆæ‰¹é‡å¤„ç†)")
        print("2. FireRedASR-LLM (é«˜ç²¾åº¦, è¾ƒæ…¢)")
        
        while True:
            try:
                choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
                if choice == "1":
                    self.model_type = "aed"
                    model_dir = "pretrained_models/FireRedASR-AED-L"
                    print("âœ… é€‰æ‹©äº† FireRedASR-AED æ¨¡å‹")
                    break
                elif choice == "2":
                    self.model_type = "llm"
                    model_dir = "pretrained_models/FireRedASR-LLM-L"
                    print("âœ… é€‰æ‹©äº† FireRedASR-LLM æ¨¡å‹")
                    break
                else:
                    print("âŒ æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return False
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„
        if not Path(model_dir).exists():
            print(f"âŒ é”™è¯¯: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
            print("è¯·ä» https://huggingface.co/fireredteam ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
            return False
        
        return model_dir
    
    def load_model(self, model_dir):
        """åŠ è½½æ¨¡å‹"""
        print(f"\nğŸ”„ æ­£åœ¨åŠ è½½ {self.model_type.upper()} æ¨¡å‹...")
        start_time = time.time()
        
        try:
            self.model = FireRedAsr.from_pretrained(self.model_type, model_dir)
            load_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}s)")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def get_decode_config(self):
        """è·å–è§£ç é…ç½®"""
        if self.model_type == "aed":
            return {
                "use_gpu": 1,
                "beam_size": 3,
                "nbest": 1,
                "decode_max_len": 0,
                "softmax_smoothing": 1.25,
                "aed_length_penalty": 0.6,
                "eos_penalty": 1.0
            }
        else:  # llm
            return {
                "use_gpu": 1,
                "beam_size": 3,
                "decode_max_len": 0,
                "decode_min_len": 0,
                "repetition_penalty": 3.0,
                "llm_length_penalty": 1.0,
                "temperature": 1.0
            }
    
    def transcribe_file(self, file_path):
        """è½¬å½•å•ä¸ªæ–‡ä»¶"""
        print(f"\nğŸ”„ å¤„ç†: {file_path.name}")
        
        try:
            uttid = file_path.stem
            decode_config = self.get_decode_config()
            
            start_time = time.time()
            results = self.model.transcribe([uttid], [str(file_path)], decode_config)
            process_time = time.time() - start_time
            
            if results and len(results) > 0:
                result = results[0]
                text = result['text']
                rtf = float(result.get('rtf', 0))
                
                print(f"âœ… è¯†åˆ«å®Œæˆ (è€—æ—¶: {process_time:.2f}s, RTF: {rtf:.4f})")
                print(f"ğŸ“ ç»“æœ: {text}")
                
                return {
                    'file': file_path.name,
                    'text': text,
                    'duration': process_time,
                    'rtf': rtf,
                    'model': self.model_type,
                    'timestamp': datetime.now().isoformat()
                }
            else:
                print(f"âŒ è¯†åˆ«å¤±è´¥: æ²¡æœ‰è¿”å›ç»“æœ")
                return None
                
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            return None
    
    def save_results(self, all_results):
        """ä¿å­˜ç»“æœåˆ°è¾“å‡ºæ–‡ä»¶å¤¹"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æ–‡æœ¬ç»“æœ
        txt_file = self.output_dir / f"transcription_results_{timestamp}.txt"
        json_file = self.output_dir / f"transcription_results_{timestamp}.json"
        
        # å†™å…¥æ–‡æœ¬æ–‡ä»¶
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"FireRedASR æ‰¹é‡è¯­éŸ³è¯†åˆ«ç»“æœ\n")
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ä½¿ç”¨æ¨¡å‹: {self.model_type.upper()}\n")
            f.write("=" * 60 + "\n\n")
            
            for i, result in enumerate(all_results, 1):
                if result:
                    f.write(f"{i}. æ–‡ä»¶: {result['file']}\n")
                    f.write(f"   è¯†åˆ«ç»“æœ: {result['text']}\n")
                    f.write(f"   å¤„ç†æ—¶é—´: {result['duration']:.2f}s\n")
                    f.write(f"   RTF: {result['rtf']:.4f}\n")
                    f.write("-" * 40 + "\n")
        
        # å†™å…¥JSONæ–‡ä»¶
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'model': self.model_type,
                    'total_files': len(all_results),
                    'successful': len([r for r in all_results if r is not None])
                },
                'results': all_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
        print(f"ğŸ“„ æ–‡æœ¬æ–‡ä»¶: {txt_file}")
        print(f"ğŸ“„ JSONæ–‡ä»¶: {json_file}")
        
        # æ ‡ç‚¹æ¢å¤å¤„ç†
        if self.enable_punctuation and all_results:
            try:
                print(f"\nğŸ”¤ å¼€å§‹æ ‡ç‚¹æ¢å¤å¤„ç†...")
                
                # åˆå§‹åŒ–æ ‡ç‚¹æ¢å¤å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
                if self.punctuation_restorer is None:
                    self.punctuation_restorer = PunctuationRestorer(
                        cache_dir=self.punctuation_model_dir,
                        chunk_size=self.punctuation_chunk_size,
                        stride=self.punctuation_stride
                    )
                
                # ç”Ÿæˆå¸¦æ ‡ç‚¹çš„æ–‡æœ¬æ–‡ä»¶
                punctuated_txt_file = self.output_dir / f"transcription_results_{timestamp}_with_punctuation.txt"
                punctuated_json_file = self.output_dir / f"transcription_results_{timestamp}_with_punctuation.json"
                
                # å¤„ç†æ¯ä¸ªç»“æœçš„æ ‡ç‚¹æ¢å¤
                punctuated_results = []
                for result in all_results:
                    if result and result.get('text'):
                        punctuated_text = self.punctuation_restorer.restore_punctuation(result['text'])
                        punctuated_result = result.copy()
                        punctuated_result['text'] = punctuated_text
                        punctuated_result['original_text'] = result['text']
                        punctuated_results.append(punctuated_result)
                    else:
                        punctuated_results.append(result)
                
                # å†™å…¥å¸¦æ ‡ç‚¹çš„æ–‡æœ¬æ–‡ä»¶
                with open(punctuated_txt_file, 'w', encoding='utf-8') as f:
                    f.write(f"FireRedASR æ‰¹é‡è¯­éŸ³è¯†åˆ«ç»“æœï¼ˆå¸¦æ ‡ç‚¹ï¼‰\n")
                    f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"ä½¿ç”¨æ¨¡å‹: {self.model_type.upper()}\n")
                    f.write("=" * 60 + "\n\n")
                    
                    for i, result in enumerate(punctuated_results, 1):
                        if result:
                            f.write(f"{i}. æ–‡ä»¶: {result['file']}\n")
                            f.write(f"   è¯†åˆ«ç»“æœ: {result['text']}\n")
                            f.write(f"   å¤„ç†æ—¶é—´: {result['duration']:.2f}s\n")
                            f.write(f"   RTF: {result['rtf']:.4f}\n")
                            f.write("-" * 40 + "\n")
                
                # å†™å…¥å¸¦æ ‡ç‚¹çš„JSONæ–‡ä»¶
                with open(punctuated_json_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'metadata': {
                            'timestamp': datetime.now().isoformat(),
                            'model': self.model_type,
                            'total_files': len(punctuated_results),
                            'successful': len([r for r in punctuated_results if r is not None]),
                            'punctuation_enabled': True
                        },
                        'results': punctuated_results
                    }, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ“„ å¸¦æ ‡ç‚¹æ–‡æœ¬æ–‡ä»¶: {punctuated_txt_file}")
                print(f"ğŸ“„ å¸¦æ ‡ç‚¹JSONæ–‡ä»¶: {punctuated_json_file}")
                
                # å¦‚æœå¯ç”¨äº†åˆ†æ®µåŠŸèƒ½ï¼Œåˆå¹¶æ‰€æœ‰æ–‡æœ¬å¹¶åˆ†æ®µ
                if self.enable_paragraph and punctuated_results:
                    try:
                        print(f"\nğŸ“‘ å¼€å§‹åˆå¹¶æ–‡æœ¬å¹¶è¿›è¡Œè‡ªç„¶æ®µåˆ†æ®µ...")
                        
                        # åˆå§‹åŒ–åˆ†æ®µå™¨
                        if self.paragraph_segmenter is None:
                            self.paragraph_segmenter = ParagraphSegmenter(
                                min_length=self.min_paragraph_length,
                                max_length=self.max_paragraph_length
                            )
                        
                        # åˆå¹¶æ‰€æœ‰è¯†åˆ«ç»“æœçš„æ–‡æœ¬
                        merged_text = ""
                        for result in punctuated_results:
                            if result and result.get('text'):
                                merged_text += result['text'] + "ã€‚"
                        
                        # æ‰§è¡Œåˆ†æ®µ
                        paragraphs = self.paragraph_segmenter.segment_paragraphs(merged_text)
                        
                        # ä¿å­˜åˆ†æ®µç»“æœï¼ˆä¼˜åŒ–çš„ä¹¦ç±æ’ç‰ˆæ ¼å¼ï¼‰
                        paragraph_txt_file = self.output_dir / f"transcription_results_{timestamp}_paragraphs.txt"
                        with open(paragraph_txt_file, 'w', encoding='utf-8') as f:
                            f.write(f"FireRedASR æ‰¹é‡è¯†åˆ«ç»“æœ\n")
                            f.write(f"\nå¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                            f.write(f"ä½¿ç”¨æ¨¡å‹: {self.model_type.upper()}\n")
                            f.write(f"æ–‡ä»¶æ•°: {len(punctuated_results)}\n")
                            f.write(f"æ®µè½æ•°: {len(paragraphs)}\n")
                            f.write("\n" + "=" * 60 + "\n\n")
                            
                            # ä½¿ç”¨ä¹¦ç±æ’ç‰ˆæ ¼å¼
                            for i, para in enumerate(paragraphs, 1):
                                # æ®µé¦–ç¼©è¿›4ä¸ªç©ºæ ¼
                                f.write(f"    {para}\n\n")
                        
                        # åŒæ—¶ç”Ÿæˆ Markdown æ ¼å¼
                        markdown_file = self.output_dir / f"transcription_results_{timestamp}_paragraphs.md"
                        with open(markdown_file, 'w', encoding='utf-8') as f:
                            # Markdown å¤´éƒ¨
                            f.write(f"# æ‰¹é‡è¯†åˆ«æ–‡ç¨¿\n\n")
                            f.write(f"**å¤„ç†æ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
                            f.write(f"**æ–‡ä»¶æ•°é‡:** {len(punctuated_results)}  \n")
                            f.write(f"**æ®µè½æ•°é‡:** {len(paragraphs)}  \n\n")
                            f.write("---\n\n")
                            
                            # æ­£æ–‡å†…å®¹
                            for i, para in enumerate(paragraphs, 1):
                                f.write(f"{para}\n\n")
                        
                        print(f"ğŸ“„ è‡ªç„¶æ®µæ ¼å¼æ–‡ä»¶: {paragraph_txt_file}")
                        print(f"   å…±åˆ†ä¸º {len(paragraphs)} ä¸ªè‡ªç„¶æ®µ")
                        
                    except Exception as e:
                        print(f"âš ï¸ åˆ†æ®µå¤„ç†å¤±è´¥: {str(e)}")
                        print("   å°†ä¿ç•™å¸¦æ ‡ç‚¹ç‰ˆæœ¬")
                
            except Exception as e:
                print(f"âš ï¸ æ ‡ç‚¹æ¢å¤å¤±è´¥: {str(e)}")
                print("   å°†ä¿ç•™æ— æ ‡ç‚¹ç‰ˆæœ¬")
    
    def run(self):
        """è¿è¡Œæ‰¹é‡è½¬å½•"""
        print("ğŸ”¥ FireRedASR æ‰¹é‡è¯­éŸ³è¯†åˆ«å·¥å…·")
        print("=" * 60)
        
        # 1. æ‰«æè¾“å…¥æ–‡ä»¶
        files = self.scan_input_files()
        if not self.display_files(files):
            return
        
        # 2. ç”¨æˆ·ç¡®è®¤
        try:
            confirm = input(f"\næ˜¯å¦ç»§ç»­å¤„ç†è¿™ {len(files)} ä¸ªæ–‡ä»¶? (y/n): ").strip().lower()
            if confirm not in ['y', 'yes', 'æ˜¯']:
                print("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        
        # 3. é€‰æ‹©æ¨¡å‹
        model_dir = self.select_model()
        if not model_dir:
            return
        
        # 4. åŠ è½½æ¨¡å‹
        if not self.load_model(model_dir):
            return
        
        # 5. æ‰¹é‡å¤„ç†
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(files)} ä¸ªæ–‡ä»¶...")
        print("=" * 60)
        
        all_results = []
        successful = 0
        
        try:
            for i, file_path in enumerate(files, 1):
                print(f"\n[{i}/{len(files)}]", end=" ")
                result = self.transcribe_file(file_path)
                all_results.append(result)
                
                if result:
                    successful += 1
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
            print(f"å·²å¤„ç† {len(all_results)} ä¸ªæ–‡ä»¶")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if self.model:
                self.model.feat_extractor.cleanup_temp_files()
        
        # 6. ä¿å­˜ç»“æœ
        if all_results:
            self.save_results(all_results)
            
            print("\n" + "=" * 60)
            print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š æ€»è®¡: {len(all_results)} ä¸ªæ–‡ä»¶, æˆåŠŸ: {successful} ä¸ª")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="FireRedASR æ‰¹é‡è¯­éŸ³è¯†åˆ«å·¥å…·")
    
    # æ ‡ç‚¹æ¢å¤ç›¸å…³å‚æ•°
    parser.add_argument('--enable-punctuation', action='store_true', default=True,
                        help='å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--disable-punctuation', action='store_true',
                        help='ç¦ç”¨æ ‡ç‚¹æ¢å¤')
    parser.add_argument('--punctuation-model-dir', type=str,
                        help='è‡ªå®šä¹‰æ ‡ç‚¹æ¢å¤æ¨¡å‹è·¯å¾„')
    parser.add_argument('--punctuation-chunk-size', type=int, default=256,
                        help='æ ‡ç‚¹æ¢å¤æ–‡æœ¬å—å¤§å°ï¼ˆé»˜è®¤: 256ï¼‰')
    parser.add_argument('--punctuation-stride', type=int, default=128,
                        help='æ ‡ç‚¹æ¢å¤æ»‘åŠ¨çª—å£æ­¥é•¿ï¼ˆé»˜è®¤: 128ï¼‰')
    
    # åˆ†æ®µç›¸å…³å‚æ•°
    parser.add_argument('--enable-paragraph', action='store_true',
                        help='å¯ç”¨è‡ªç„¶æ®µåˆ†æ®µåŠŸèƒ½ï¼ˆå°†åˆå¹¶æ‰€æœ‰æ–‡æœ¬ååˆ†æ®µï¼‰')
    parser.add_argument('--min-paragraph-length', type=int, default=50,
                        help='æœ€å°æ®µè½é•¿åº¦ï¼ˆé»˜è®¤: 50å­—ï¼‰')
    parser.add_argument('--max-paragraph-length', type=int, default=500,
                        help='æœ€å¤§æ®µè½é•¿åº¦ï¼ˆé»˜è®¤: 500å­—ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
    if not Path("fireredasr").exists():
        print("âŒ é”™è¯¯: è¯·åœ¨ FireRedASR é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        print("å½“å‰ç›®å½•åº”è¯¥åŒ…å« fireredasr/ æ–‡ä»¶å¤¹")
        return
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONPATH'] = str(Path.cwd()) + ":" + os.environ.get('PYTHONPATH', '')
    
    try:
        transcriber = BatchTranscriber()
        
        # è®¾ç½®æ ‡ç‚¹æ¢å¤å‚æ•°
        if args.disable_punctuation:
            transcriber.enable_punctuation = False
        else:
            transcriber.enable_punctuation = True
        
        if args.punctuation_model_dir:
            transcriber.punctuation_model_dir = args.punctuation_model_dir
        transcriber.punctuation_chunk_size = args.punctuation_chunk_size
        transcriber.punctuation_stride = args.punctuation_stride
        
        # è®¾ç½®åˆ†æ®µå‚æ•°
        transcriber.enable_paragraph = args.enable_paragraph
        transcriber.min_paragraph_length = args.min_paragraph_length
        transcriber.max_paragraph_length = args.max_paragraph_length
        
        transcriber.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
FireRedASR æ¨¡å‹å¿«é€Ÿæµ‹è¯•è„šæœ¬

æ”¯æŒéŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶æµ‹è¯•

ç”¨æ³•ï¼š
  # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
  python test_models.py --model aed --input examples/wav/BAC009S0764W0121.wav
  python test_models.py --model llm --input examples/wav/BAC009S0764W0121.wav
  
  # æµ‹è¯•è§†é¢‘æ–‡ä»¶
  python test_models.py --model aed --input examples/video/sample.mp4
  python test_models.py --model both --input examples/video/sample.mp4
  
  # å‘åå…¼å®¹
  python test_models.py --model both --wav examples/wav/BAC009S0764W0121.wav
"""

import argparse
import time
from pathlib import Path

from fireredasr.models.fireredasr import FireRedAsr
from fireredasr.utils.video_audio import is_video_file, is_audio_file

def test_model(model_type, input_path, use_gpu=True):
    """æµ‹è¯•æŒ‡å®šæ¨¡å‹"""
    print(f"\n{'='*50}")
    print(f"æµ‹è¯• {model_type.upper()} æ¨¡å‹")
    print(f"{'='*50}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶ç±»å‹
    if is_video_file(input_path):
        print(f"ğŸ“¹ è¾“å…¥æ–‡ä»¶ç±»å‹: è§†é¢‘æ–‡ä»¶")
    elif is_audio_file(input_path) or input_path.endswith('.wav'):
        print(f"ğŸµ è¾“å…¥æ–‡ä»¶ç±»å‹: éŸ³é¢‘æ–‡ä»¶")
    else:
        print(f"â“ è¾“å…¥æ–‡ä»¶ç±»å‹: æœªçŸ¥æ ¼å¼ï¼Œå°è¯•ä½œä¸ºéŸ³é¢‘å¤„ç†")
    
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_path}")
    
    # æ¨¡å‹è·¯å¾„é…ç½®
    model_paths = {
        'aed': 'pretrained_models/FireRedASR-AED-L',
        'llm': 'pretrained_models/FireRedASR-LLM-L'
    }
    
    # è§£ç å‚æ•°é…ç½®
    decode_configs = {
        'aed': {
            "use_gpu": 1 if use_gpu else 0,
            "beam_size": 3,
            "nbest": 1,
            "decode_max_len": 0,
            "softmax_smoothing": 1.25,
            "aed_length_penalty": 0.6,
            "eos_penalty": 1.0
        },
        'llm': {
            "use_gpu": 1 if use_gpu else 0,
            "beam_size": 3,
            "decode_max_len": 0,
            "decode_min_len": 0,
            "repetition_penalty": 3.0,
            "llm_length_penalty": 1.0,
            "temperature": 1.0
        }
    }
    
    try:
        # åŠ è½½æ¨¡å‹
        print(f"æ­£åœ¨åŠ è½½ {model_type.upper()} æ¨¡å‹...")
        start_time = time.time()
        model = FireRedAsr.from_pretrained(model_type, model_paths[model_type])
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}s)")
        
        # è¿›è¡Œæ¨ç†
        print(f"æ­£åœ¨å¤„ç†è¾“å…¥æ–‡ä»¶: {input_path}")
        uttid = Path(input_path).stem
        
        start_time = time.time()
        results = model.transcribe([uttid], [input_path], decode_configs[model_type])
        inference_time = time.time() - start_time
        
        # è¾“å‡ºç»“æœ
        if results and len(results) > 0:
            result = results[0]
            print(f"ğŸ¯ è¯†åˆ«ç»“æœ: {result['text']}")
            print(f"ğŸ“Š æ¨ç†æ—¶é—´: {inference_time:.2f}s")
            print(f"ğŸ“Š RTF: {result['rtf']}")
        else:
            print("âŒ æœªè·å¾—è¯†åˆ«ç»“æœ")
        
        return True
        
    except Exception as e:
        print(f"âŒ {model_type.upper()} æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='FireRedASR æ¨¡å‹æµ‹è¯•è„šæœ¬')
    parser.add_argument('--model', type=str, choices=['aed', 'llm', 'both'], 
                       default='both', help='é€‰æ‹©æµ‹è¯•æ¨¡å‹ (é»˜è®¤: both)')
    parser.add_argument('--input', type=str, 
                       help='æµ‹è¯•è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰')
    parser.add_argument('--wav', type=str, 
                       default='examples/wav/BAC009S0764W0121.wav',
                       help='æµ‹è¯•éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰')
    parser.add_argument('--cpu', action='store_true', 
                       help='ä½¿ç”¨CPUæ¨¡å¼ï¼ˆé»˜è®¤ä½¿ç”¨GPUï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_file = args.input if args.input else args.wav
    
    if not input_file:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šè¾“å…¥æ–‡ä»¶ (--input æˆ– --wav)")
        return
    
    if not Path(input_file).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    use_gpu = not args.cpu
    
    print("ğŸ”¥ FireRedASR æ¨¡å‹æµ‹è¯•")
    print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"è®¡ç®—è®¾å¤‡: {'GPU' if use_gpu else 'CPU'}")
    
    success_count = 0
    total_count = 0
    
    try:
        if args.model in ['aed', 'both']:
            total_count += 1
            if test_model('aed', input_file, use_gpu):
                success_count += 1
        
        if args.model in ['llm', 'both']:
            total_count += 1
            if test_model('llm', input_file, use_gpu):
                success_count += 1
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print("\nğŸ§¹ æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        # æ³¨æ„ï¼šåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è®¿é—®æ¨¡å‹çš„æ¸…ç†æ–¹æ³•
        # ä½†ç”±äºæ¨¡å‹å¯èƒ½åœ¨ä¸åŒä½œç”¨åŸŸï¼Œæˆ‘ä»¬ä¾èµ–ASRFeatExtractorçš„è‡ªåŠ¨æ¸…ç†
    
    # æ€»ç»“
    print(f"\n{'='*50}")
    print(f"æµ‹è¯•å®Œæˆ: {success_count}/{total_count} ä¸ªæ¨¡å‹æµ‹è¯•æˆåŠŸ")
    print(f"{'='*50}")

if __name__ == "__main__":
    main()
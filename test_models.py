#!/usr/bin/env python3
"""
FireRedASR æ¨¡å‹å¿«é€Ÿæµ‹è¯•è„šæœ¬
ç”¨æ³•ï¼š
  python test_models.py --model aed --wav examples/wav/BAC009S0764W0121.wav
  python test_models.py --model llm --wav examples/wav/BAC009S0764W0121.wav
  python test_models.py --model both --wav examples/wav/BAC009S0764W0121.wav
"""

import argparse
import time
from fireredasr.models.fireredasr import FireRedAsr

def test_model(model_type, wav_path, use_gpu=True):
    """æµ‹è¯•æŒ‡å®šæ¨¡å‹"""
    print(f"\n{'='*50}")
    print(f"æµ‹è¯• {model_type.upper()} æ¨¡å‹")
    print(f"{'='*50}")
    
    # æ¨¡å‹è·¯å¾„é…ç½®
    model_paths = {
        'aed': 'pretrained_models/FireRedASR-AED-L',
        'llm': 'pretrained_models/FireRedASR-LLM-L'
    }
    
    # è§£ç å‚æ•°é…ç½®
    decode_configs = {
        'aed': {
            "use_gpu": 1 if use_gpu else 0,
            "beam_size": 3,
            "nbest": 1,
            "decode_max_len": 0,
            "softmax_smoothing": 1.25,
            "aed_length_penalty": 0.6,
            "eos_penalty": 1.0
        },
        'llm': {
            "use_gpu": 1 if use_gpu else 0,
            "beam_size": 3,
            "decode_max_len": 0,
            "decode_min_len": 0,
            "repetition_penalty": 3.0,
            "llm_length_penalty": 1.0,
            "temperature": 1.0
        }
    }
    
    try:
        # åŠ è½½æ¨¡å‹
        print(f"æ­£åœ¨åŠ è½½ {model_type.upper()} æ¨¡å‹...")
        start_time = time.time()
        model = FireRedAsr.from_pretrained(model_type, model_paths[model_type])
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}s)")
        
        # è¿›è¡Œæ¨ç†
        print(f"æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶: {wav_path}")
        uttid = wav_path.split('/')[-1].replace('.wav', '')
        
        start_time = time.time()
        results = model.transcribe([uttid], [wav_path], decode_configs[model_type])
        inference_time = time.time() - start_time
        
        # è¾“å‡ºç»“æœ
        if results and len(results) > 0:
            result = results[0]
            print(f"ğŸ¯ è¯†åˆ«ç»“æœ: {result['text']}")
            print(f"ğŸ“Š æ¨ç†æ—¶é—´: {inference_time:.2f}s")
            print(f"ğŸ“Š RTF: {result['rtf']}")
        else:
            print("âŒ æœªè·å¾—è¯†åˆ«ç»“æœ")
        
        return True
        
    except Exception as e:
        print(f"âŒ {model_type.upper()} æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description='FireRedASR æ¨¡å‹æµ‹è¯•è„šæœ¬')
    parser.add_argument('--model', type=str, choices=['aed', 'llm', 'both'], 
                       default='both', help='é€‰æ‹©æµ‹è¯•æ¨¡å‹ (é»˜è®¤: both)')
    parser.add_argument('--wav', type=str, 
                       default='examples/wav/BAC009S0764W0121.wav',
                       help='æµ‹è¯•éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--cpu', action='store_true', 
                       help='ä½¿ç”¨CPUæ¨¡å¼ï¼ˆé»˜è®¤ä½¿ç”¨GPUï¼‰')
    
    args = parser.parse_args()
    
    use_gpu = not args.cpu
    
    print("ğŸ”¥ FireRedASR æ¨¡å‹æµ‹è¯•")
    print(f"éŸ³é¢‘æ–‡ä»¶: {args.wav}")
    print(f"è®¡ç®—è®¾å¤‡: {'GPU' if use_gpu else 'CPU'}")
    
    success_count = 0
    total_count = 0
    
    if args.model in ['aed', 'both']:
        total_count += 1
        if test_model('aed', args.wav, use_gpu):
            success_count += 1
    
    if args.model in ['llm', 'both']:
        total_count += 1
        if test_model('llm', args.wav, use_gpu):
            success_count += 1
    
    # æ€»ç»“
    print(f"\n{'='*50}")
    print(f"æµ‹è¯•å®Œæˆ: {success_count}/{total_count} ä¸ªæ¨¡å‹æµ‹è¯•æˆåŠŸ")
    print(f"{'='*50}")

if __name__ == "__main__":
    main()
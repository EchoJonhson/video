#!/usr/bin/env python3
"""
å¹¶è¡Œå¤„ç†å™¨æ¨¡å—
- æ¸©å’Œçš„å¤šçº¿ç¨‹éŸ³é¢‘å¤„ç†
- æ™ºèƒ½è´Ÿè½½å‡è¡¡
- èµ„æºç›‘æ§å’Œè‡ªé€‚åº”è°ƒæ•´
"""

import os
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue, Empty
from typing import List, Dict, Callable, Any
import psutil
from pathlib import Path


class ParallelProcessor:
    """å¹¶è¡Œå¤„ç†å™¨"""
    
    def __init__(self, max_workers: int = 8, resource_check_interval: int = 5):
        self.max_workers = max_workers
        self.resource_check_interval = resource_check_interval
        self.executor = None
        self.running = False
        self.processed_count = 0
        self.total_count = 0
        self.start_time = None
        self.resource_monitor_thread = None
        self.should_throttle = False
        
        print(f"ğŸ”§ åˆå§‹åŒ–å¹¶è¡Œå¤„ç†å™¨: {max_workers} çº¿ç¨‹")
    
    def __enter__(self):
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)
        self.running = True
        self.start_time = time.time()
        
        # å¯åŠ¨èµ„æºç›‘æ§çº¿ç¨‹
        self.resource_monitor_thread = threading.Thread(
            target=self._monitor_resources, 
            daemon=True
        )
        self.resource_monitor_thread.start()
        
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.running = False
        if self.executor:
            self.executor.shutdown(wait=True)
        if self.resource_monitor_thread:
            self.resource_monitor_thread.join(timeout=1)
    
    def _monitor_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        while self.running:
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_percent = psutil.virtual_memory().percent
                
                # å¦‚æœ CPU æˆ–å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¯ç”¨èŠ‚æµ
                if cpu_percent > 80 or memory_percent > 85:
                    if not self.should_throttle:
                        print(f"âš ï¸ ç³»ç»Ÿè´Ÿè½½è¿‡é«˜ (CPU: {cpu_percent:.1f}%, å†…å­˜: {memory_percent:.1f}%)ï¼Œå¯ç”¨èŠ‚æµæ¨¡å¼")
                        self.should_throttle = True
                else:
                    if self.should_throttle:
                        print("âœ… ç³»ç»Ÿè´Ÿè½½æ­£å¸¸ï¼Œå…³é—­èŠ‚æµæ¨¡å¼")
                        self.should_throttle = False
                
                # èŠ‚æµç­‰å¾…
                if self.should_throttle:
                    time.sleep(2)
                else:
                    time.sleep(self.resource_check_interval)
                    
            except Exception as e:
                print(f"âš ï¸ èµ„æºç›‘æ§å‡ºé”™: {e}")
                time.sleep(self.resource_check_interval)
    
    def process_batch(self, 
                     items: List[Any], 
                     process_func: Callable,
                     description: str = "å¤„ç†",
                     batch_size: int = None) -> List[Any]:
        """æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        
        if not items:
            return []
        
        self.total_count = len(items)
        self.processed_count = 0
        results = []
        
        print(f"ğŸš€ å¼€å§‹{description}: {self.total_count} ä¸ªä»»åŠ¡ï¼Œ{self.max_workers} çº¿ç¨‹")
        
        # å¦‚æœæŒ‡å®šäº†æ‰¹æ¬¡å¤§å°ï¼Œåˆ†æ‰¹å¤„ç†
        if batch_size and batch_size < len(items):
            batches = [items[i:i + batch_size] for i in range(0, len(items), batch_size)]
            
            for batch_idx, batch in enumerate(batches, 1):
                print(f"ğŸ“¦ å¤„ç†ç¬¬ {batch_idx}/{len(batches)} æ‰¹æ¬¡ ({len(batch)} ä¸ªä»»åŠ¡)")
                batch_results = self._process_single_batch(batch, process_func, description)
                results.extend(batch_results)
                
                # æ‰¹æ¬¡é—´æš‚åœï¼Œé¿å…ç³»ç»Ÿè¿‡è½½
                if batch_idx < len(batches):
                    time.sleep(1)
        else:
            results = self._process_single_batch(items, process_func, description)
        
        elapsed = time.time() - self.start_time
        print(f"âœ… {description}å®Œæˆ: {len(results)}/{self.total_count} æˆåŠŸ (è€—æ—¶: {elapsed:.2f}s)")
        
        return results
    
    def _process_single_batch(self, items: List[Any], process_func: Callable, description: str) -> List[Any]:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        futures = {}
        results = []
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯éŸ³é¢‘è½¬å½•ä»»åŠ¡ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        is_audio_task = "éŸ³é¢‘è½¬å½•" in description
        
        # æäº¤ä»»åŠ¡
        for i, item in enumerate(items):
            # å¦‚æœç³»ç»Ÿè´Ÿè½½è¿‡é«˜ï¼Œç­‰å¾…
            while self.should_throttle:
                time.sleep(0.5)
            
            # å¯¹äºéŸ³é¢‘è½¬å½•ä»»åŠ¡ï¼Œåœ¨æäº¤ä¹‹é—´å¢åŠ å°å»¶è¿Ÿï¼Œé¿å…ç¬æ—¶å‹åŠ›
            if is_audio_task and self.max_workers > 1 and i > 0:
                time.sleep(0.1)  # 100mså»¶è¿Ÿ
            
            future = self.executor.submit(self._safe_process, process_func, item)
            futures[future] = item
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(futures):
            try:
                result = future.result()
                if result is not None:
                    results.append(result)
                
                self.processed_count += 1
                self._print_progress(description)
                
                # å¯¹äºéŸ³é¢‘è½¬å½•ï¼Œæ¯å¤„ç†å®Œä¸€ä¸ªå°±æ¸…ç†ä¸€æ¬¡å†…å­˜
                if is_audio_task and self.processed_count % 5 == 0:
                    import gc
                    gc.collect()
                
            except Exception as e:
                item = futures[future]
                print(f"âŒ å¤„ç†å¤±è´¥: {item} - {str(e)}")
        
        return results
    
    def _safe_process(self, process_func: Callable, item: Any) -> Any:
        """å®‰å…¨å¤„ç†å•ä¸ªä»»åŠ¡"""
        try:
            return process_func(item)
        except Exception as e:
            print(f"âŒ ä»»åŠ¡å¤„ç†å¼‚å¸¸: {str(e)}")
            return None
    
    def _print_progress(self, description: str):
        """æ‰“å°è¿›åº¦ä¿¡æ¯"""
        if self.total_count > 0:
            progress = (self.processed_count / self.total_count) * 100
            elapsed = time.time() - self.start_time
            
            # æ¯ 10% æˆ–æ¯ 10 ä¸ªä»»åŠ¡æ‰“å°ä¸€æ¬¡è¿›åº¦
            if self.processed_count % max(1, self.total_count // 10) == 0 or self.processed_count % 10 == 0:
                avg_time = elapsed / self.processed_count if self.processed_count > 0 else 0
                remaining = (self.total_count - self.processed_count) * avg_time
                
                print(f"ğŸ“Š {description}è¿›åº¦: {self.processed_count}/{self.total_count} "
                      f"({progress:.1f}%) - å‰©ä½™: {remaining:.1f}s")


class AudioBatchProcessor:
    """éŸ³é¢‘æ‰¹å¤„ç†å™¨"""
    
    def __init__(self, max_workers: int = 8):
        self.max_workers = max_workers
    
    def process_audio_segments(self, 
                             segments: List[Path], 
                             transcribe_func: Callable,
                             batch_size: int = 2,
                             model_type: str = 'aed') -> List[Dict]:
        """å¹¶è¡Œå¤„ç†éŸ³é¢‘ç‰‡æ®µï¼ˆæ”¯æŒLLMæ¨¡å‹ä¼˜åŒ–ï¼‰"""
        
        def process_segment(segment_path):
            """å¤„ç†å•ä¸ªéŸ³é¢‘ç‰‡æ®µ"""
            try:
                start_time = time.time()
                
                # è°ƒç”¨è½¬å½•å‡½æ•°
                result = transcribe_func(segment_path)
                
                process_time = time.time() - start_time
                
                if result:
                    if 'process_time' not in result:
                        result['process_time'] = process_time
                    return result
                else:
                    print(f"âš ï¸ è½¬å½•å¤±è´¥: {segment_path}")
                    return None
                    
            except Exception as e:
                print(f"âŒ å¤„ç†éŸ³é¢‘ç‰‡æ®µå¤±è´¥ {segment_path}: {str(e)}")
                return None
        
        # å¯¹äºLLMæ¨¡å‹ï¼Œå¢åŠ æ‰¹æ¬¡é—´çš„å»¶è¿Ÿ
        if model_type == 'llm' and self.max_workers > 1:
            print("ğŸ”§ LLMæ¨¡å‹å¹¶è¡Œä¼˜åŒ–ï¼šå¢åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œå‡å°‘å†…å­˜å‹åŠ›")
        
        # ä½¿ç”¨å¹¶è¡Œå¤„ç†å™¨
        with ParallelProcessor(max_workers=self.max_workers) as processor:
            # å¦‚æœæ˜¯LLMæ¨¡å‹ä¸”ä½¿ç”¨å¹¶è¡Œï¼Œå‡å°æ‰¹æ¬¡å¤§å°
            if model_type == 'llm' and self.max_workers > 1:
                batch_size = 1  # LLMæ¨¡å‹æ¯æ¬¡åªå¤„ç†ä¸€ä¸ª
                
            results = processor.process_batch(
                segments, 
                process_segment, 
                description="éŸ³é¢‘è½¬å½•",
                batch_size=batch_size
            )
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ
        valid_results = [r for r in results if r is not None]
        
        if valid_results:
            total_audio_time = sum(r.get('duration', 0) for r in valid_results)
            total_process_time = sum(r.get('process_time', 0) for r in valid_results)
            avg_rtf = total_process_time / total_audio_time if total_audio_time > 0 else 0
            
            print(f"ğŸ“ˆ å¹¶è¡Œå¤„ç†ç»Ÿè®¡:")
            print(f"   éŸ³é¢‘æ€»æ—¶é•¿: {total_audio_time:.2f}s")
            print(f"   å¤„ç†æ€»æ—¶é—´: {total_process_time:.2f}s")
            print(f"   å¹³å‡å®æ—¶å› å­: {avg_rtf:.4f}")
            print(f"   å¹¶è¡ŒåŠ é€Ÿæ¯”: {total_audio_time / total_process_time:.2f}x")
        
        return valid_results


def test_parallel_processor():
    """æµ‹è¯•å¹¶è¡Œå¤„ç†å™¨"""
    import random
    
    def dummy_task(item):
        # æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡
        time.sleep(random.uniform(0.1, 0.5))
        return f"å¤„ç†å®Œæˆ: {item}"
    
    test_items = [f"ä»»åŠ¡_{i}" for i in range(20)]
    
    with ParallelProcessor(max_workers=4) as processor:
        results = processor.process_batch(test_items, dummy_task, "æµ‹è¯•ä»»åŠ¡")
    
    print(f"æµ‹è¯•ç»“æœ: {len(results)} ä¸ªä»»åŠ¡å®Œæˆ")


if __name__ == "__main__":
    test_parallel_processor()